{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "from seaborn import heatmap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7210ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_data = pd.read_csv(\"./data/HIGGS-002.zip\", header=None)\n",
    "higgs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b901a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "higgs_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_data[0].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(higgs_data.corr())\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_data[\"intercept\"] = 1\n",
    "feature_names = list(higgs_data.drop(columns=0))\n",
    "features = higgs_data.drop(columns=0).values\n",
    "features = MinMaxScaler().fit_transform(features)\n",
    "target = higgs_data[0].copy()\n",
    "\n",
    "(\n",
    "    X, \n",
    "    X_test, \n",
    "    y, \n",
    "    y_test\n",
    ")=train_test_split(features, target.values, test_size=0.25, random_state=3136, stratify=target.values)\n",
    "\n",
    "\n",
    "# # Oversample to balance the data\n",
    "# n0 = y.shape[0] - y.sum()\n",
    "# idx1 = np.array(range(y.shape[0]))[(y==1).flatten()]\n",
    "# new_idx = np.random.choice(idx1, size=n0, replace=True)\n",
    "\n",
    "# X = np.concatenate([X[(y == 0).flatten()], X[new_idx]])\n",
    "# y = np.concatenate([y[(y == 0).flatten()], y[new_idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bff49",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78271d42",
   "metadata": {},
   "source": [
    "## Determine Optimization Parameters for Momentum SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "opt_candidates={\n",
    "    \"lr\":  [0.1, 1, 5, 10],\n",
    "    \"batch_size\": [16, 64, 256, 1024],\n",
    "    \"momentum\": [0, 0.5, 0.9],\n",
    "    \"max_epoch\": [25],\n",
    "}\n",
    "\n",
    "mu = 0\n",
    "\n",
    "results = {}\n",
    "for params in product(*opt_candidates.values()):\n",
    "    lr, batch_size, momentum, max_epoch = params\n",
    "    param_key = \"_\".join(str(x) for x in params)\n",
    "    \n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w = MomentumStochasticGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            mu=mu,\n",
    "            lr=lr,\n",
    "            moment=momentum,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        preds = sigmoid(X_val@w)\n",
    "        loss = neg_log_lik(preds, y_val, w, mu)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[param_key] = np.mean(cv_results)\n",
    "    \n",
    "\n",
    "best_params = min(results, key=lambda key: results[key])\n",
    "print(f\"BEST: {best_params}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955948b",
   "metadata": {},
   "source": [
    "### Determine Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c72630",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_candidates = np.arange(0, 0.01, 0.001)\n",
    "lr, batch_size, momentum, max_epoch = [float(x) if \".\" in x else int(x) for x in best_params.split(\"_\")]\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "results = {}\n",
    "for mu in mu_candidates:\n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        w = MomentumStochasticGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            mu=mu,\n",
    "            lr=lr,\n",
    "            moment=momentum,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "\n",
    "        probs = sigmoid(X_val@w) #> 0.5\n",
    "        loss = roc_auc_score(y_val, probs)\n",
    "        cv_results.append(loss)\n",
    "\n",
    "    results[str(mu)] = np.mean(cv_results)\n",
    "\n",
    "selected_mu = float(max(results, key=lambda key: results[key]))\n",
    "print(\"BEST MU: \", selected_mu)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57489198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(penalty=\"none\", max_iter=1000)\n",
    "logreg.fit(X, y)\n",
    "test_pred = logreg.predict(X_test)\n",
    "print(\"Balanced Accuracy\", balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb468b7",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce05f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = MomentumStochasticGradient(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    mu=selected_mu,\n",
    "    lr=lr,\n",
    "    moment=momentum,\n",
    "    batch_size=batch_size,\n",
    "    max_epoch=max_epoch,\n",
    ")\n",
    "test_prob = sigmoid(X_test@w)\n",
    "#test_pred = (test_prob > (y_train.sum()/y_train.shape[0])).astype(int)\n",
    "test_pred = (test_prob > 0.5).astype(int)\n",
    "print(\"\\nTEST LOSS: \",neg_log_lik(test_prob, y_test, w, mu=selected_mu))\n",
    "print(\"Balanced Accuracy\", balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, feature in  sorted(zip(w, feature_names)):\n",
    "    print(feature, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "fig.plot(cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e99bf",
   "metadata": {},
   "source": [
    "## Determine Optimization Parameters for AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "opt_candidates={\n",
    "    \"lr\":  [0.1, 1, 5, 10],\n",
    "    \"batch_size\": [16, 64, 256, 512, 1024],\n",
    "    \"max_epoch\": [40],\n",
    "}\n",
    "\n",
    "mu = 0\n",
    "\n",
    "results = {}\n",
    "for params in product(*opt_candidates.values()):\n",
    "    lr, batch_size, max_epoch = params\n",
    "    param_key = \"_\".join(str(x) for x in params)\n",
    "    \n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w = AdaGrad(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            mu=mu,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        preds = sigmoid(X_val@w)\n",
    "        loss = neg_log_lik(preds, y_val, w, mu)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[param_key] = np.mean(cv_results)\n",
    "    \n",
    "\n",
    "best_params = min(results, key=lambda key: results[key])\n",
    "print(f\"BEST: {best_params}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e46679b",
   "metadata": {},
   "source": [
    "### Determine Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_candidates = np.arange(0, 0.01, 0.001)\n",
    "lr, batch_size, max_epoch = [int(x) for x in best_params.split(\"_\")]\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "results = {}\n",
    "for mu in mu_candidates:\n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        w = AdaGrad(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            mu=mu,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "\n",
    "        probs = sigmoid(X_val@w) #> 0.5\n",
    "        loss = roc_auc_score(y_val, probs)\n",
    "        cv_results.append(loss)\n",
    "\n",
    "    results[str(mu)] = np.mean(cv_results)\n",
    "\n",
    "selected_mu = float(max(results, key=lambda key: results[key]))\n",
    "print(\"BEST MU: \", selected_mu)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5d716",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fecf2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = AdaGrad(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    mu=selected_mu,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    max_epoch=max_epoch,\n",
    ")\n",
    "test_prob = sigmoid(X_test@w)\n",
    "#test_pred = (test_prob > (y_train.sum()/y_train.shape[0])).astype(int)\n",
    "test_pred = (test_prob > 0.5).astype(int)\n",
    "print(\"\\nTEST LOSS: \",neg_log_lik(test_prob, y_test, w, mu=selected_mu))\n",
    "print(\"Balanced Accuracy\", balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c477d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, feature in  sorted(zip(w, feature_names)):\n",
    "    print(feature, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "fig.plot(cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc1026",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf888f25",
   "metadata": {},
   "source": [
    "## Determine Optimization Parameters for Momentum Stochastic Subgradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5829c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop intercept\n",
    "X = X[:, :-1]\n",
    "y_svm = y.copy()\n",
    "y_svm[y_svm == 0 ] = -1\n",
    "y = y_svm.reshape(-1,1)\n",
    "# Set large C for strict model\n",
    "C = 1e18\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "opt_candidates={\n",
    "    \"lr\":  [0.1, 1, 10],\n",
    "    \"batch_size\": [16, 64, 256, 1024],\n",
    "    \"momentum\": [0, 0.5, 0.9],\n",
    "    \"max_epoch\": [25],\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for params in product(*opt_candidates.values()):\n",
    "    lr, batch_size, momentum, max_epoch = params\n",
    "    param_key = \"_\".join(str(x) for x in params)\n",
    "    \n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w0, w = MomentumSubGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            C=C,\n",
    "            lr=lr,\n",
    "            moment=momentum,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        loss = HingeLossl2(C, w, w0, X_val, y_val)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[param_key] = np.mean(cv_results)\n",
    "    \n",
    "best_params = min(results, key=lambda key: results[key])\n",
    "print(f\"BEST: {best_params}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081dd88",
   "metadata": {},
   "source": [
    "## Tune Parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4433607",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=3, shuffle=True, random_state=3136)\n",
    "\n",
    "C_candidates = [1e-1, 1e0,1e1, 1e2, 1e3, 1e4]\n",
    "lr, batch_size, momentum, max_epoch = [float(x) if \".\" in x else int(x) for x in best_params.split(\"_\")]\n",
    "\n",
    "\n",
    "results = {}\n",
    "for C in C_candidates:\n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w0, w = MomentumSubGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            C=C,\n",
    "            lr=lr,\n",
    "            moment=momentum,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        pred = (w0+X_val@w) > 0\n",
    "        y_val[y_val == -1] = 0\n",
    "        loss = balanced_accuracy_score(y_val, pred)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[str(C)] = np.mean(cv_results)\n",
    "    \n",
    "selected_C = float(max(results, key=lambda key: results[key]))\n",
    "print(\"BEST C: \", selected_C)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_C = 10000\n",
    "lr, batch_size, momentum, max_epoch = 0.1, 16, 0.5, 25\n",
    "w0, w = MomentumSubGradient(\n",
    "            X=X,\n",
    "            y=y,\n",
    "            C=selected_C,\n",
    "            lr=lr,\n",
    "            moment=momentum,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "test_pred = (w0+X_test[:,:-1]@w) > 0\n",
    "#print(\"\\nTEST LOSS: \",HingeLossl2(selected_C, w, w0, X_test[:,:-1], y_test))\n",
    "print(\"Balanced Accuracy\", balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, feature in  sorted(zip(w, feature_names)):\n",
    "    print(feature, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afec110",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "fig.plot(cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7070905",
   "metadata": {},
   "source": [
    "## Determine Optimization Parameters for AdaSubgradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set large C for strict model\n",
    "C = 1e18\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "opt_candidates={\n",
    "    \"lr\":  [0.1, 1, 5, 10],\n",
    "    \"batch_size\": [16, 64, 256, 512, 1024],\n",
    "    \"max_epoch\": [40],\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for params in product(*opt_candidates.values()):\n",
    "    lr, batch_size, max_epoch = params\n",
    "    param_key = \"_\".join(str(x) for x in params)\n",
    "    \n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w0, w = AdaSubGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            C=C,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        loss = HingeLossl2(C, w, w0, X_val, y_val)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[param_key] = np.mean(cv_results)\n",
    "    \n",
    "best_params = min(results, key=lambda key: results[key])\n",
    "print(f\"BEST: {best_params}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c9b63",
   "metadata": {},
   "source": [
    "### Tune Parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=3136)\n",
    "\n",
    "C_candidates = list(np.arange(100, 1000, 25))  + [1e1, 1, 1e-1, 1e-2]\n",
    "lr, batch_size, max_epoch = [float(x) if \".\" in x else int(x) for x in best_params.split(\"_\")]\n",
    "\n",
    "\n",
    "results = {}\n",
    "for C in C_candidates:\n",
    "    cv_results = []\n",
    "    for train_index, val_index in splitter.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        w0, w = AdaSubGradient(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            C=C,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "        \n",
    "        pred = (w0+X_val@w) > 0\n",
    "        y_val[y_val == -1] = 0\n",
    "        loss = balanced_accuracy_score(y_val, pred)\n",
    "        cv_results.append(loss)\n",
    "        \n",
    "    results[str(C)] = np.mean(cv_results)\n",
    "    \n",
    "selected_C = float(max(results, key=lambda key: results[key]))\n",
    "print(\"BEST C: \", selected_C)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169045c",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed15116",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w = AdaSubGradient(\n",
    "            X=X,\n",
    "            y=y,\n",
    "            C=selected_C,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            max_epoch=max_epoch,\n",
    "        )\n",
    "test_pred = (w0+X_test[:,:-1]@w) > 0\n",
    "print(\"\\nTEST LOSS: \",HingeLossl2(selected_C, w, w0, X_test[:,:-1], y_test))\n",
    "print(\"Balanced Accuracy\", balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d92f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, feature in  sorted(zip(w, feature_names)):\n",
    "    print(feature, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1723971",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred))\n",
    "fig.plot(cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486d8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
